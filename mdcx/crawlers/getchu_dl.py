#!/usr/bin/env python3
import contextlib
import re
import time
import unicodedata
import urllib.parse

from lxml import etree

from mdcx.config.manager import config
from mdcx.models.log_buffer import LogBuffer


def get_title(html):
    result = html.xpath('//meta[@property="og:title"]/@content')
    return result[0].strip() if result else ""


def get_studio(html):
    return html.xpath("string(//td[text()='ã‚µãƒ¼ã‚¯ãƒ«']/following-sibling::td)")


def get_release(html):
    result = html.xpath("//td[contains(text(),'é…ä¿¡é–‹å§‹æ—¥')]/following-sibling::td/text()")
    return result[0].replace("/", "-") if result and re.search(r"\d+", result[0]) else ""


def get_year(release):
    try:
        result = str(re.search(r"\d{4}", release).group())
        return result
    except Exception:
        return release


def get_director(html):
    return html.xpath('string(//td[text()="ä½œè€…"]/following-sibling::td)').strip()


def get_runtime(html):
    result = html.xpath("//td[contains(text(),'ç”»åƒæ•°&ãƒšãƒ¼ã‚¸æ•°')]/following-sibling::td/text()")
    if result:
        result = re.findall(r"\d*", result[0])
    return result[0] if result else ""


def get_tag(html):
    result = html.xpath('//td[text()="è¶£å‘"]/following-sibling::td/a/text()')
    return ",".join(result) if result else ""


def get_cover(html):
    result = html.xpath('//meta[@property="og:image"]/@content')
    return result[0] if result else ""


def get_outline(html):
    return html.xpath('string(//td[text()="ä½œå“å†…å®¹"]/following-sibling::td)').strip()


def get_extrafanart(html):
    result_list = html.xpath("//a[contains(@href,'/data/item_img/') and @class='highslide']/@href")
    result = []
    for each in result_list:
        result.append(f"https://dl.getchu.com{each}")
    return result


async def main(
    number,
    appoint_url="",
    **kwargs,
):
    start_time = time.time()
    website_name = "getchu"
    LogBuffer.req().write(f"-> {website_name}")
    real_url = appoint_url
    cover_url = ""
    image_cut = ""
    image_download = True
    url_search = ""
    web_info = "\n       "
    LogBuffer.info().write(" \n    ğŸŒ dl_getchu")
    debug_info = ""
    cookies = {"adult_check_flag": "1"}
    if not real_url and ("DLID" in number.upper() or "ITEM" in number.upper() or "GETCHU" in number.upper()):
        id = re.findall(r"\d+", number)[0]
        real_url = f"https://dl.getchu.com/i/item{id}"  # real_url = 'https://dl.getchu.com/i/item4024984'

    try:  # æ•è·ä¸»åŠ¨æŠ›å‡ºçš„å¼‚å¸¸
        if not real_url:
            keyword = unicodedata.normalize(
                "NFC", number.replace("â—", " ")
            )  # Mac æŠŠä¼šæ‹†æˆä¸¤ä¸ªå­—ç¬¦ï¼Œå³ NFDï¼Œè€Œç½‘é¡µè¯·æ±‚ä½¿ç”¨çš„æ˜¯ NFC
            with contextlib.suppress(Exception):  # è½¬æ¢ä¸ºå¸¸è§æ—¥æ–‡ï¼Œæ¯”å¦‚ï½ è½¬æ¢æˆ ã€œ
                keyword = keyword.encode("cp932").decode("shift_jis")
            keyword2 = urllib.parse.quote_plus(
                keyword, encoding="EUC-JP"
            )  # quote() ä¸ç¼–ç æ–œçº¿ï¼Œç©ºæ ¼â€˜ â€™ç¼–ç ä¸ºâ€˜%20â€™ï¼›quote_plus() ä¼šç¼–ç æ–œçº¿ä¸ºâ€˜%2Fâ€™; ç©ºæ ¼â€˜ â€™ç¼–ç ä¸ºâ€˜+â€™
            url_search = f"https://dl.getchu.com/search/search_list.php?dojin=1&search_category_id=&search_keyword={keyword2}&btnWordSearch=%B8%A1%BA%F7&action=search&set_category_flag=1"
            debug_info = f"æœç´¢åœ°å€: {url_search} "
            LogBuffer.info().write(web_info + debug_info)

            # ========================================================================æœç´¢ç•ªå·
            html_search, error = await config.async_client.get_text(url_search, cookies=cookies, encoding="euc-jp")
            if html_search is None:
                debug_info = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {error} "
                LogBuffer.info().write(web_info + debug_info)
                raise Exception(debug_info)
            html = etree.fromstring(html_search, etree.HTMLParser())
            res_list = html.xpath("//table/tr/td[@valign='top' and not (@align)]/div/a")
            for each in res_list:
                temp_url = each.get("href")
                temp_title = each.xpath("string(.)")
                if temp_url and "/item" in temp_url and temp_title and temp_title.startswith(number):
                    real_url = temp_url
                    break
            else:
                debug_info = "æœç´¢ç»“æœ: æœªåŒ¹é…åˆ°ç•ªå·ï¼"
                LogBuffer.info().write(web_info + debug_info)
                raise Exception(debug_info)

        if real_url:
            debug_info = f"ç•ªå·åœ°å€: {real_url} "
            LogBuffer.info().write(web_info + debug_info)

            html_content, error = await config.async_client.get_text(real_url, cookies=cookies, encoding="euc-jp")
            if html_content is None:
                debug_info = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {error} "
                LogBuffer.info().write(web_info + debug_info)
                raise Exception(debug_info)
            html_info = etree.fromstring(html_content, etree.HTMLParser())
            number = "DLID-" + re.findall(r"\d+", real_url)[0]
            title = get_title(html_info)
            if not title:
                debug_info = "æ•°æ®è·å–å¤±è´¥: æœªè·å–åˆ°titleï¼"
                LogBuffer.info().write(web_info + debug_info)
                raise Exception(debug_info)
            outline = get_outline(html_info)
            actor = ""
            actor_photo = {"": ""}
            cover_url = get_cover(html_info)
            tag = get_tag(html_info)
            studio = get_studio(html_info)
            release = get_release(html_info)
            year = get_year(release)
            runtime = get_runtime(html_info)
            score = ""
            series = ""
            director = get_director(html_info)
            publisher = ""
            extrafanart = get_extrafanart(html_info)
            mosaic = "åŒäºº"
            try:
                dic = {
                    "number": number,
                    "title": title,
                    "originaltitle": title,
                    "actor": actor,
                    "outline": outline,
                    "originalplot": outline,
                    "tag": tag,
                    "release": release,
                    "year": year,
                    "runtime": runtime,
                    "score": score,
                    "series": series,
                    "director": director,
                    "studio": studio,
                    "publisher": publisher,
                    "source": "dl_getchu",
                    "actor_photo": actor_photo,
                    "thumb": cover_url,
                    "poster": cover_url,
                    "extrafanart": extrafanart,
                    "trailer": "",
                    "image_download": image_download,
                    "image_cut": image_cut,
                    "mosaic": mosaic,
                    "website": real_url,
                    "wanted": "",
                }
                debug_info = "æ•°æ®è·å–æˆåŠŸï¼"
                LogBuffer.info().write(web_info + debug_info)

            except Exception as e:
                debug_info = f"æ•°æ®ç”Ÿæˆå‡ºé”™: {str(e)}"
                LogBuffer.info().write(web_info + debug_info)
                raise Exception(debug_info)
    except Exception as e:
        # print(traceback.format_exc())
        LogBuffer.error().write(str(e))
        dic = {
            "title": "",
            "thumb": "",
            "website": "",
        }
    dic = {website_name: {"zh_cn": dic, "zh_tw": dic, "jp": dic}}
    LogBuffer.req().write(f"({round(time.time() - start_time)}s) ")
    return dic


if __name__ == "__main__":
    # yapf: disable
    # print(main('ã‚³ãƒ³ãƒ“ãƒ‹â—‹â—‹Z ç¬¬ä¸‰è©± ã‚ãªãŸã€ãƒ¤ãƒ³ã‚¯ãƒ¬ãƒãƒã§ã™ã‚ˆã­ã€‚æ—¦é‚£ã«ä¸‡å¼•ããŒãƒãƒ¬ã¦ã„ã„ã‚“ã§ã™ã‹ï¼Ÿ'))
    # print(main('[PoRO]ã‚¨ãƒ­ã‚³ãƒ³ãƒ’ã‚™ãƒ‹åº—é•· æ³£ãã¸ã‚™ãè“®ã£è‘‰ãƒ»æ ï½ãŠä»•ç½®ãã—ã‚™ã‡ã‚‰ã—ãƒãƒŠãƒé€¸æ©Ÿï½'))
    # print(main('æ¯ã¡ã‚ƒã‚“ã®å‹é”ã«ã‚·ã‚³ã£ã¦ã‚‹ã¨ã“ã‚è¦‹ã‚‰ã‚ŒãŸã€‚'))
    # print(main('DLID4024984'))
    print(main('ã€å§«å§‹ã‚ã‚»ãƒƒã‚¯ã‚¹æµå‡ºã€‘äººæ°—Yâ—uâ—berãƒªã‚¢ãƒ«å½¼å¥³ã¨ã®ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒãƒ¡æ’®ã‚Šæ˜ åƒæµå‡º!!åˆè©£å¸°ã‚Šã«æŒ¯è¢–å§¿ã®ã¾ã¾å½¼å¥³ã«ã—ã‚ƒã¶ã‚‰ã›ç”Ÿä¸­å‡ºã—ï¼ç”Ÿã€…ã—ã„æ˜ åƒãƒ‡ãƒ¼ã‚¿'))  # print(main('å¥½ãã«ã—ã‚„ãŒã‚Œ GOTcomics'))    # æ›¸ç±ï¼Œæ²¡æœ‰ç•ªå·
