import asyncio
import random
from io import BytesIO
from typing import Any, Callable, Optional, Union

import aiofiles
import httpx
from aiolimiter import AsyncLimiter
from curl_cffi import AsyncSession, Response
from curl_cffi.requests.exceptions import ConnectionError, RequestException, Timeout
from curl_cffi.requests.session import HttpMethod
from curl_cffi.requests.utils import not_set
from PIL import Image


class AsyncWebLimiters:
    def __init__(self):
        self.limiters: dict[str, AsyncLimiter] = {
            "127.0.0.1": AsyncLimiter(300, 1),
            "localhost": AsyncLimiter(300, 1),
        }

    def get(self, key: str, rate: float = 5, period: float = 1) -> AsyncLimiter:
        """é»˜è®¤å¯¹æ‰€æœ‰åŸŸåå¯ç”¨ 5 req/s çš„é€Ÿç‡é™åˆ¶"""
        return self.limiters.setdefault(key, AsyncLimiter(rate, period))

    def remove(self, key: str):
        if key in self.limiters:
            del self.limiters[key]


class AsyncWebClient:
    def __init__(
        self,
        *,
        proxy: Optional[str] = None,
        retry: int = 3,
        timeout: float,
        log_fn: Optional[Callable[[str], None]] = None,
        limiters: Optional[AsyncWebLimiters] = None,
        loop=None,
    ):
        self.retry = retry
        self.proxy = proxy
        self.curl_session = AsyncSession(
            loop=loop,
            max_clients=50,
            verify=False,
            max_redirects=20,
            timeout=timeout,
            impersonate=random.choice(["chrome123", "chrome124", "chrome131", "chrome136", "firefox133", "firefox135"]),
        )

        self.log_fn = log_fn if log_fn is not None else lambda _: None
        self.limiters = limiters if limiters is not None else AsyncWebLimiters()

    def _prepare_headers(self, url: Optional[str] = None, headers: Optional[dict[str, str]] = None) -> dict[str, str]:
        """é¢„å¤„ç†è¯·æ±‚å¤´"""
        if not headers:
            headers = {}

        # æ ¹æ®URLè®¾ç½®ç‰¹å®šçš„Referer
        if url:
            if "getchu" in url:
                headers.update({"Referer": "http://www.getchu.com/top.html"})
            elif "xcity" in url:
                headers.update(
                    {"referer": "https://xcity.jp/result_published/?genre=%2Fresult_published%2F&q=2&sg=main&num=60"}
                )
            elif "javbus" in url:
                headers.update({"Referer": "https://www.javbus.com/"})
            elif "giga" in url and "cookie_set.php" not in url:
                headers.update({"Referer": "https://www.giga-web.jp/top.html"})

        return headers

    async def request(
        self,
        method: HttpMethod,
        url: str,
        *,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
        data: Optional[Union[dict[str, str], list[tuple], str, BytesIO, bytes]] = None,
        json_data: Optional[dict[str, Any]] = None,
        timeout: Optional[httpx.Timeout] = None,
        stream: bool = False,
        allow_redirects: bool = True,
    ) -> tuple[Optional[Response], str]:
        """
        æ‰§è¡Œè¯·æ±‚çš„é€šç”¨æ–¹æ³•

        Args:
            url: è¯·æ±‚URL
            headers: è¯·æ±‚å¤´
            cookies: cookies
            use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†
            data: è¡¨å•æ•°æ®
            json_data: JSONæ•°æ®
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´, è¦†ç›–å®¢æˆ·ç«¯é»˜è®¤å€¼

        Returns:
            tuple[Optional[Response], str]: (å“åº”å¯¹è±¡, é”™è¯¯ä¿¡æ¯)
        """
        try:
            u = httpx.URL(url)
            headers = self._prepare_headers(url, headers)
            await self.limiters.get(u.host).acquire()
            retry_count = self.retry
            error_msg = ""
            for attempt in range(retry_count):
                # é‡‡ç”¨ä¿å®ˆçš„é‡è¯•ç­–ç•¥, é™¤ç‰¹å®šçŠ¶æ€ç å¤–ä¸è¿›è¡Œé‡è¯•
                retry = False
                try:
                    resp: Response = await self.curl_session.request(
                        method,
                        url,
                        proxy=self.proxy if use_proxy else None,
                        headers=headers,
                        cookies=cookies,
                        data=data,
                        json=json_data,
                        timeout=timeout or not_set,
                        stream=stream,
                        allow_redirects=allow_redirects,
                    )
                    # æ£€æŸ¥å“åº”çŠ¶æ€
                    if resp.status_code >= 300 and not (resp.status_code == 302 and resp.headers.get("Location")):
                        error_msg = f"HTTP {resp.status_code}"
                        retry = resp.status_code in (
                            408,  # Request Timeout
                            429,  # Too Many Requests
                            504,  # Gateway Timeout
                        )
                    else:
                        self.log_fn(f"âœ… {method} {url} æˆåŠŸ")
                        return resp, ""
                except Timeout:
                    error_msg = "è¿æ¥è¶…æ—¶"
                except ConnectionError as e:
                    error_msg = f"è¿æ¥é”™è¯¯: {str(e)}"
                except RequestException as e:
                    error_msg = f"è¯·æ±‚å¼‚å¸¸: {str(e)} {e.code}"
                except Exception as e:
                    error_msg = f"curl-cffi å¼‚å¸¸: {str(e)}"
                if not retry:
                    break
                self.log_fn(f"ğŸ”´ {method} {url} å¤±è´¥: {error_msg} ({attempt + 1}/{retry_count})")
                # é‡è¯•å‰ç­‰å¾…
                if attempt < retry_count - 1:
                    await asyncio.sleep(attempt * 3 + 2)
            return None, f"{method} {url} å¤±è´¥: {error_msg}"
        except Exception as e:
            error_msg = f"{method} {url} æœªçŸ¥é”™è¯¯:  {str(e)}"
            self.log_fn(f"ğŸ”´ {error_msg}")
            return None, error_msg

    async def get_text(
        self,
        url: str,
        *,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        encoding: str = "utf-8",
        use_proxy: bool = True,
    ) -> tuple[Optional[str], str]:
        """è¯·æ±‚æ–‡æœ¬å†…å®¹"""
        resp, error = await self.request("GET", url, headers=headers, cookies=cookies, use_proxy=use_proxy)
        if resp is None:
            return None, error
        try:
            resp.encoding = encoding
            return resp.text, error
        except Exception as e:
            return None, f"æ–‡æœ¬è§£æå¤±è´¥: {str(e)}"

    async def get_content(
        self,
        url: str,
        *,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
    ) -> tuple[Optional[bytes], str]:
        """è¯·æ±‚äºŒè¿›åˆ¶å†…å®¹"""
        resp, error = await self.request("GET", url, headers=headers, cookies=cookies, use_proxy=use_proxy)
        if resp is None:
            return None, error

        return resp.content, ""

    async def get_json(
        self,
        url: str,
        *,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
    ) -> tuple[Optional[Any], str]:
        """è¯·æ±‚JSONæ•°æ®"""
        response, error = await self.request("GET", url, headers=headers, cookies=cookies, use_proxy=use_proxy)
        if response is None:
            return None, error
        try:
            return response.json(), ""
        except Exception as e:
            return None, f"JSONè§£æå¤±è´¥: {str(e)}"

    async def post_text(
        self,
        url: str,
        *,
        data: Optional[Union[dict[str, str], list[tuple], str, BytesIO, bytes]] = None,
        json_data: Optional[dict[str, Any]] = None,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        encoding: str = "utf-8",
        use_proxy: bool = True,
    ) -> tuple[Optional[str], str]:
        """POST è¯·æ±‚, è¿”å›å“åº”æ–‡æœ¬å†…å®¹"""
        response, error = await self.request(
            "POST", url, data=data, json_data=json_data, headers=headers, cookies=cookies, use_proxy=use_proxy
        )
        if response is None:
            return None, error
        try:
            response.encoding = encoding
            return response.text, ""
        except Exception as e:
            return None, f"æ–‡æœ¬è§£æå¤±è´¥: {str(e)}"

    async def post_json(
        self,
        url: str,
        *,
        data: Optional[Union[dict[str, str], list[tuple], str, BytesIO, bytes]] = None,
        json_data: Optional[dict[str, Any]] = None,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
    ) -> tuple[Optional[Any], str]:
        """POST è¯·æ±‚, è¿”å›å“åº”JSONæ•°æ®"""
        response, error = await self.request(
            "POST", url, data=data, json_data=json_data, headers=headers, cookies=cookies, use_proxy=use_proxy
        )
        if error or response is None:
            return None, error

        try:
            return response.json(), ""
        except Exception as e:
            return None, f"JSONè§£æå¤±è´¥: {str(e)}"

    async def post_content(
        self,
        url: str,
        *,
        data: Optional[Union[dict[str, str], list[tuple], str, BytesIO, bytes]] = None,
        json_data: Optional[dict[str, Any]] = None,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
    ) -> tuple[Optional[bytes], str]:
        """POSTè¯·æ±‚, è¿”å›äºŒè¿›åˆ¶å“åº”"""
        response, error = await self.request(
            "POST", url, data=data, json_data=json_data, headers=headers, cookies=cookies, use_proxy=use_proxy
        )
        if error or response is None:
            return None, error

        return response.content, ""

    async def get_filesize(self, url: str, *, use_proxy: bool = True) -> Optional[int]:
        """è·å–æ–‡ä»¶å¤§å°"""
        response, error = await self.request("HEAD", url, use_proxy=use_proxy)
        if response is None:
            self.log_fn(f"ğŸ”´ è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {url} {error}")
            return None
        if response.status_code < 400:
            return int(response.headers.get("Content-Length"))
        self.log_fn(f"ğŸ”´ è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {url} HTTP {response.status_code}")
        return None

    async def download(self, url: str, file_path: str, *, use_proxy: bool = True) -> bool:
        """
        ä¸‹è½½æ–‡ä»¶. å½“æ–‡ä»¶è¾ƒå¤§æ—¶åˆ†å—ä¸‹è½½

        Args:
            url: ä¸‹è½½é“¾æ¥
            file_path: ä¿å­˜è·¯å¾„
            use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†

        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        # è·å–æ–‡ä»¶å¤§å°
        file_size = await self.get_filesize(url, use_proxy=use_proxy)
        # åˆ¤æ–­æ˜¯ä¸æ˜¯webpæ–‡ä»¶
        webp = False
        if file_path.endswith("jpg") and ".webp" in url:
            webp = True

        MB = 1024**2
        # 2 MB ä»¥ä¸Šä½¿ç”¨åˆ†å—ä¸‹è½½, ä¸æ¸…æ¥šä¸ºä»€ä¹ˆ webp ä¸åˆ†å—, å¯èƒ½æ˜¯å› ä¸ºè¦è½¬æ¢æˆ jpg
        if file_size and file_size > 2 * MB and not webp:
            return await self._download_chunks(url, file_path, file_size, use_proxy)

        content, error = await self.get_content(url, use_proxy=use_proxy)
        if not content:
            self.log_fn(f"ğŸ”´ ä¸‹è½½å¤±è´¥: {url} {error}")
            return False
        if not webp:
            try:
                async with aiofiles.open(file_path, "wb") as f:
                    await f.write(content)
                return True
            except Exception as e:
                self.log_fn(f"ğŸ”´ æ–‡ä»¶å†™å…¥å¤±è´¥: {url} {file_path} {str(e)}")
                return False
        try:
            byte_stream = BytesIO(content)
            img: Image.Image = Image.open(byte_stream)
            if img.mode == "RGBA":
                img = img.convert("RGB")
            img.save(file_path, quality=95, subsampling=0)
            img.close()
            return True
        except Exception as e:
            self.log_fn(f"ğŸ”´ WebPè½¬æ¢å¤±è´¥: {url} {file_path} {str(e)}")
            return False

    async def _download_chunks(self, url: str, file_path: str, file_size: int, use_proxy: bool = True) -> bool:
        """åˆ†å—ä¸‹è½½å¤§æ–‡ä»¶"""
        # åˆ†å—ï¼Œæ¯å— 1 MB
        MB = 1024**2
        each_size = min(1 * MB, file_size)
        parts = [(s, min(s + each_size, file_size)) for s in range(0, file_size, each_size)]

        self.log_fn(f"ğŸ“¦ åˆ†å—ä¸‹è½½: {url} {len(parts)} ä¸ªåˆ†å—, æ€»å¤§å°: {file_size} bytes")

        # å…ˆåˆ›å»ºæ–‡ä»¶å¹¶é¢„åˆ†é…ç©ºé—´
        try:
            async with aiofiles.open(file_path, "wb") as f:
                await f.truncate(file_size)
        except Exception as e:
            self.log_fn(f"ğŸ”´ æ–‡ä»¶åˆ›å»ºå¤±è´¥: {url} {str(e)}")
            return False

        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
        semaphore = asyncio.Semaphore(10)  # é™åˆ¶å¹¶å‘æ•°
        tasks = []

        for i, (start, end) in enumerate(parts):
            task = self._download_chunk(semaphore, url, file_path, start, end, i, use_proxy)
            tasks.append(task)

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä¸‹è½½ä»»åŠ¡
        try:
            errors = await asyncio.gather(*tasks, return_exceptions=True)
            # æ£€æŸ¥æ‰€æœ‰ä»»åŠ¡æ˜¯å¦æˆåŠŸ
            for i, err in enumerate(errors):
                if isinstance(err, Exception):
                    self.log_fn(f"ğŸ”´ åˆ†å— {i} ä¸‹è½½å¤±è´¥: {url} {str(err)}")
                    return False
                elif err:
                    self.log_fn(f"ğŸ”´ åˆ†å— {i} ä¸‹è½½å¤±è´¥: {url} {err}")
                    return False
            self.log_fn(f"âœ… å¤šåˆ†å—ä¸‹è½½å®Œæˆ: {url} {file_path}")
            return True
        except Exception as e:
            self.log_fn(f"ğŸ”´ å¹¶å‘ä¸‹è½½å¼‚å¸¸: {url} {str(e)}")
            return False

    async def _download_chunk(
        self,
        semaphore: asyncio.Semaphore,
        url: str,
        file_path: str,
        start: int,
        end: int,
        chunk_id: int,
        use_proxy: bool = True,
    ) -> Optional[str]:
        """ä¸‹è½½å•ä¸ªåˆ†å—"""
        async with semaphore:
            res, error = await self.request(
                "GET",
                url,
                headers={"Range": f"bytes={start}-{end}"},
                use_proxy=use_proxy,
                stream=True,
            )
            if res is None:
                return error
        # å†™å…¥æ–‡ä»¶
        async with aiofiles.open(file_path, "rb+") as fp:
            await fp.seek(start)
            await fp.write(await res.acontent())
        return ""
