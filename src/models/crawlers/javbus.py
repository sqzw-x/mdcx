#!/usr/bin/env python3
import json
import re
import time  # yapf: disable # NOQA: E402

import urllib3
from lxml import etree

from models.base.web_compat import get_text
from models.config.manager import config
from models.core.json_data import LogBuffer

urllib3.disable_warnings()  # yapf: disable


# import traceback


def get_title(html):
    result = html.xpath("//h3/text()")
    if result:
        result = result[0].strip()
    else:
        result = ""
    return result


def getWebNumber(html, number):
    result = html.xpath('//span[@class="header"][contains(text(), "è­˜åˆ¥ç¢¼:")]/../span[2]/text()')
    return result[0] if result else number


def getActor(html):
    try:
        result = (
            str(html.xpath('//div[@class="star-name"]/a/text()')).strip(" ['']").replace("'", "").replace(", ", ",")
        )
    except Exception:
        result = ""
    return result


def getActorPhoto(html, url):
    actor = html.xpath('//div[@class="star-name"]/../a/img/@title')
    photo = html.xpath('//div[@class="star-name"]/../a/img/@src')
    data = {}
    if len(actor) == len(photo):
        for i in range(len(actor)):
            if "http" not in photo[i]:
                data[actor[i]] = url + photo[i]
            else:
                data[actor[i]] = photo[i]
    else:
        for each in actor:
            data[each] = ""
    return data


def getCover(html, url):  # è·å–å°é¢é“¾æ¥
    result = html.xpath('//a[@class="bigImage"]/@href')
    if result:
        if "http" not in result[0]:
            cover_url = url + result[0]
        else:
            cover_url = result[0]
    else:
        cover_url = ""
    return cover_url


def get_poster_url(cover_url):  # è·å–å°å°é¢é“¾æ¥
    poster_url = ""
    if "/pics/" in cover_url:
        poster_url = cover_url.replace("/cover/", "/thumb/").replace("_b.jpg", ".jpg")
    elif "/imgs/" in cover_url:
        poster_url = cover_url.replace("/cover/", "/thumbs/").replace("_b.jpg", ".jpg")
    return poster_url


def getRelease(html):  # è·å–å‘è¡Œæ—¥æœŸ
    result = html.xpath('//span[@class="header"][contains(text(), "ç™¼è¡Œæ—¥æœŸ:")]/../text()')
    if result:
        result = result[0].strip()
    else:
        result = ""
    return result


def getYear(release):
    try:
        result = str(re.search(r"\d{4}", release).group())
        return result
    except Exception:
        return release[:4]


def getMosaic(html):
    select_tab = str(html.xpath('//li[@class="active"]/a/text()'))
    if "æœ‰ç¢¼" in select_tab:
        mosaic = "æœ‰ç "
    else:
        mosaic = "æ— ç "
    return mosaic


def getRuntime(html):
    result = html.xpath('//span[@class="header"][contains(text(), "é•·åº¦:")]/../text()')
    if result:
        result = result[0].strip()
        result = re.findall(r"\d+", result)
        if result:
            result = result[0]
        else:
            result = ""
    else:
        result = ""
    return result


def getStudio(html):
    result = html.xpath('//a[contains(@href, "/studio/")]/text()')
    if result:
        result = result[0].strip()
    else:
        result = ""
    return result


def getPublisher(html, studio):  # è·å–å‘è¡Œå•†
    result = html.xpath('//a[contains(@href, "/label/")]/text()')
    if result:
        result = result[0].strip()
    else:
        result = studio
    return result


def getDirector(html):  # è·å–å¯¼æ¼”
    result = html.xpath('//a[contains(@href, "/director/")]/text()')
    if result:
        result = result[0].strip()
    else:
        result = ""
    return result


def getSeries(html):
    result = html.xpath('//a[contains(@href, "/series/")]/text()')
    if result:
        result = result[0].strip()
    else:
        result = ""
    return result


def getExtraFanart(html, url):  # è·å–å°é¢é“¾æ¥
    result = html.xpath("//div[@id='sample-waterfall']/a/@href")
    if result:
        new_list = []
        for each in result:
            if "http" not in each:
                each = url + each
            new_list.append(each)
    else:
        new_list = ""
    return new_list


def getTag(html):  # è·å–æ ‡ç­¾
    result = html.xpath('//span[@class="genre"]/label/a[contains(@href, "/genre/")]/text()')
    if result:
        result = str(result).strip(" ['']").replace("'", "").replace(", ", ",")
    else:
        result = ""
    return result


def get_real_url(
    number,
    url_type,
    javbus_url,
    json_log,
    headers,
    cookie,
):  # è·å–è¯¦æƒ…é¡µé“¾æ¥
    if url_type == "us":  # æ¬§ç¾
        url_search = "https://www.javbus.hair/search/" + number
    elif url_type == "censored":  # æœ‰ç 
        url_search = javbus_url + "/search/" + number + "&type=&parent=ce"
    else:  # æ— ç 
        url_search = javbus_url + "/uncensored/search/" + number + "&type=0&parent=uc"

    debug_info = f"æœç´¢åœ°å€: {url_search} "
    LogBuffer.info().write(debug_info)
    # ========================================================================æœç´¢ç•ªå·
    html_search, error = get_text(url_search, headers=headers)
    # åˆ¤æ–­æ˜¯å¦éœ€è¦ç™»å½•
    if html_search is None:
        debug_info = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {error} "
        LogBuffer.info().write(debug_info)
        raise Exception(debug_info)
    if "lostpasswd" in html_search:
        # æœ‰ cookie
        if cookie:
            raise Exception("Cookie æ— æ•ˆï¼è¯·é‡æ–°å¡«å†™ Cookie æˆ–æ›´æ–°èŠ‚ç‚¹ï¼")
        else:
            raise Exception("å½“å‰èŠ‚ç‚¹éœ€è¦å¡«å†™ Cookie æ‰èƒ½åˆ®å‰Šï¼è¯·åˆ° è®¾ç½®-ç½‘ç»œ å¡«å†™ Cookie æˆ–æ›´æ¢èŠ‚ç‚¹ï¼")

    html = etree.fromstring(html_search, etree.HTMLParser())
    url_list = html.xpath("//a[@class='movie-box']/@href")
    for each in url_list:
        each_url = each.upper().replace("-", "")
        number_1 = "/" + number.upper().replace(".", "").replace("-", "")
        number_2 = number_1 + "_"
        if each_url.endswith(number_1) or number_2 in each_url:
            debug_info = f"ç•ªå·åœ°å€: {each} "
            LogBuffer.info().write(debug_info)
            return each
    debug_info = "æœç´¢ç»“æœ: æœªåŒ¹é…åˆ°ç•ªå·ï¼"
    LogBuffer.info().write(debug_info)
    raise Exception(debug_info)


def main(
    number,
    appoint_url="",
    language="jp",
    mosaic="",
):
    start_time = time.time()
    website_name = "javbus"
    LogBuffer.req().write(f"-> {website_name}")
    real_url = appoint_url
    javbus_url = getattr(config, "javbus_website", "https://www.javbus.com")
    headers = config.headers
    cookie = config.javbus
    headers_o = {
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7,ja;q=0.6",
        "cookie": cookie,
    }
    headers.update(headers_o)

    title = ""
    cover_url = ""
    poster_url = ""
    image_download = False
    image_cut = "right"
    dic = {}
    debug_info = ""
    json_log = {}
    LogBuffer.info().write(" \n    ğŸŒ javbus")

    try:
        if not real_url:
            # æ¬§ç¾å»æœç´¢ï¼Œå…¶ä»–å°è¯•ç›´æ¥æ‹¼æ¥åœ°å€ï¼Œæ²¡æœ‰ç»“æœæ—¶å†æœç´¢
            if "." in number or re.search(r"[-_]\d{2}[-_]\d{2}[-_]\d{2}", number):  # æ¬§ç¾å½±ç‰‡
                number = number.replace("-", ".").replace("_", ".")
                real_url = get_real_url(number, "us", javbus_url, json_log, headers, cookie)
            else:
                real_url = javbus_url + "/" + number
                if number.upper().startswith("CWP") or number.upper().startswith("LAF"):
                    temp_number = number.replace("-0", "-")
                    if temp_number[-2] == "-":
                        temp_number = temp_number.replace("-", "-0")
                    real_url = javbus_url + "/" + temp_number

        debug_info = f"ç•ªå·åœ°å€: {real_url} "
        LogBuffer.info().write(debug_info)
        htmlcode, error = get_text(real_url, headers=headers)

        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç™»å½•
        if htmlcode is None:
            debug_info = f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {error} "
            LogBuffer.info().write(debug_info)
            raise Exception(debug_info)
        if "lostpasswd" in htmlcode:
            # æœ‰ cookie
            if cookie:
                raise Exception("Cookie æ— æ•ˆï¼è¯·é‡æ–°å¡«å†™ Cookie æˆ–æ›´æ–°èŠ‚ç‚¹ï¼")
            else:
                raise Exception("å½“å‰èŠ‚ç‚¹éœ€è¦å¡«å†™ Cookie æ‰èƒ½åˆ®å‰Šï¼è¯·åˆ° è®¾ç½®-ç½‘ç»œ å¡«å†™ Cookie æˆ–æ›´æ¢èŠ‚ç‚¹ï¼")

        if htmlcode is None:
            # æœ‰404æ—¶å°è¯•å†æ¬¡æœç´¢ DV-1175
            if "404" not in error:
                debug_info = f"ç•ªå·åœ°å€:{real_url} \n       ç½‘ç»œè¯·æ±‚é”™è¯¯: {error} "
                LogBuffer.info().write(debug_info)
                raise Exception(debug_info)

            # æ¬§ç¾çš„ä¸å†æœç´¢
            if "." in number:
                debug_info = "æœªåŒ¹é…åˆ°ç•ªå·ï¼"
                LogBuffer.info().write(debug_info)
                raise Exception(debug_info)

            # æ— ç æœç´¢ç»“æœ
            elif mosaic == "æ— ç " or mosaic == "ç„¡ç¢¼":
                real_url = get_real_url(number, "uncensored", javbus_url, json_log, headers, cookie)

            # æœ‰ç æœç´¢ç»“æœ
            else:
                real_url = get_real_url(number, "censored", javbus_url, json_log, headers, cookie)

            htmlcode, error = get_text(real_url, headers=headers)
            if htmlcode is None:
                debug_info = "æœªåŒ¹é…åˆ°ç•ªå·ï¼"
                LogBuffer.info().write(debug_info)
                raise Exception(debug_info)

        # è·å–è¯¦æƒ…é¡µå†…å®¹
        html_info = etree.fromstring(htmlcode, etree.HTMLParser())
        title = get_title(html_info)
        if not title:
            debug_info = "æ•°æ®è·å–å¤±è´¥: æœªè·å–åˆ°title"
            LogBuffer.info().write(debug_info)
            raise Exception(debug_info)
        number = getWebNumber(html_info, number)  # è·å–ç•ªå·ï¼Œç”¨æ¥æ›¿æ¢æ ‡é¢˜é‡Œçš„ç•ªå·
        title = title.replace(number, "").strip()
        actor = getActor(html_info)  # è·å–actor
        actor_photo = getActorPhoto(html_info, javbus_url)
        cover_url = getCover(html_info, javbus_url)  # è·å–cover
        poster_url = get_poster_url(cover_url)
        release = getRelease(html_info)
        year = getYear(release)
        tag = getTag(html_info)
        mosaic = getMosaic(html_info)
        if mosaic == "æ— ç ":
            image_cut = "center"
            if "_" in number and poster_url:  # ä¸€æœ¬é“ï¼Œå¹¶ä¸”æœ‰å°å›¾æ—¶ï¼Œä¸‹è½½poster
                image_download = True
            elif "HEYZO" in number and len(poster_url.replace(javbus_url + "/imgs/thumbs/", "")) == 7:
                image_download = True
            else:
                poster_url = ""  # éä¸€æœ¬é“çš„æ— ç /æ¬§ç¾å½±ç‰‡ï¼Œæ¸…ç©ºå°å›¾åœ°å€ï¼Œå› ä¸ºå°å›¾éƒ½æ˜¯æœªè£å‰ªçš„ä½åˆ†è¾¨ç‡å›¾ç‰‡
        runtime = getRuntime(html_info)
        studio = getStudio(html_info)
        publisher = getPublisher(html_info, studio)
        director = getDirector(html_info)
        series = getSeries(html_info)
        extrafanart = getExtraFanart(html_info, javbus_url)
        if "KMHRS" in number:  # å‰§ç…§ç¬¬ä¸€å¼ æ˜¯é«˜æ¸…å›¾
            image_download = True
            if extrafanart:
                poster_url = extrafanart[0]
        try:
            dic = {
                "number": number,
                "title": title,
                "originaltitle": title,
                "actor": actor,
                "outline": "",
                "originalplot": "",
                "tag": tag,
                "release": release,
                "year": year,
                "runtime": runtime,
                "score": "",
                "series": series,
                "director": director,
                "studio": studio,
                "publisher": publisher,
                "source": "javbus",
                "website": real_url,
                "actor_photo": actor_photo,
                "cover": cover_url,
                "poster": poster_url,
                "extrafanart": extrafanart,
                "trailer": "",
                "image_download": image_download,
                "image_cut": image_cut,
                "mosaic": mosaic,
                "wanted": "",
            }
            debug_info = "æ•°æ®è·å–æˆåŠŸï¼"
            LogBuffer.info().write(debug_info)
        except Exception as e:
            debug_info = f"æ•°æ®ç”Ÿæˆå‡ºé”™: {str(e)}"
            LogBuffer.info().write(debug_info)
            raise Exception(debug_info)
    except Exception as e:
        LogBuffer.error().write(str(e))
        dic = {
            "title": "",
            "cover": "",
            "website": "",
        }
    dic = {website_name: {"zh_cn": dic, "zh_tw": dic, "jp": dic}}
    js = json.dumps(
        dic,
        ensure_ascii=False,
        sort_keys=False,
        indent=4,
        separators=(",", ": "),
    )  # .encode('UTF-8')
    LogBuffer.req().write(f"({round((time.time() - start_time))}s) ")
    return js


if __name__ == "__main__":
    # yapf: disable
    # print(main('LAFBD-034'))    # cwp,cwpbd æ•°å­—ä¸º2ä½æ—¶ä¸å¸¦0
    print(main('PMAXVR-008'))  # print(main('cwpbd-034'))    # cwp,cwpbd æ•°å­—ä¸º2ä½æ—¶ä¸å¸¦0  # print(main('FC2-1262472'))    # æ— ç»“æœ  # print(main('STARS-199'))    # ç¦æ­¢  # print(main('EDVR-043'))    # æ— ç»“æœ  # print(main('SSIS-243'))  # print(main('ABW-015'))  # print(main('DASD-972'))  # print(main('ss-036'))    # æ— ç»“æœ  # print(main('KMHRS-050'))  # print(main('KV-115'))    # æ— ç»“æœ  # print(main('070621_001'))  # print(main('heyzo-1031'))  # print(main('heyzo-0811'))  # print(main('heyzo-1673'))  # print(main('dv-1175'))    # æ— ç»“æœï¼Œé€šè¿‡æœç´¢æœ‰ç»“æœ  # print(main('dv1175'))  # print(main('ssni-644'))  # print(main('010115-001'))  # print(main('ssni644'))  # print(main('BigTitsatWork-17-09-26'))  # print(main('BrazzersExxtra.21.02.01'))  # print(main('KA-001'))   # æ— ç»“æœ  # print(main('012715-793'))  # print(main('ssni-644', "https://www.javbus.com/SSNI-644"))  # print(main('ssni-802', ""))  # print(main('DirtyMasseur.20.07.26', "https://www.javbus.hair/DirtyMasseur-21-01-31"))
