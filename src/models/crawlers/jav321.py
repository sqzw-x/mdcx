#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import json
import re
import time  # yapf: disable # NOQA: E402

import urllib3
from lxml import etree

from models.base.web import post_html

urllib3.disable_warnings()  # yapf: disable


# import Function.config as cf
# import traceback


def getActorPhoto(actor):
    actor = actor.split(',')
    data = {}
    for i in actor:
        actor_photo = {i: ''}
        data.update(actor_photo)
    return data


def getTitle(response):
    return str(re.findall(r'<h3>(.+) <small>', response)).strip(" ['']")


def getActor(response):
    if re.search(r'<a href="/star/\S+">(\S+)</a> &nbsp;', response):
        return str(re.findall(r'<a href="/star/\S+">(\S+)</a> &nbsp;', response)).strip(" [',']").replace('\'', '')
    elif re.search(r'<a href="/heyzo_star/\S+">(\S+)</a> &nbsp;', response):
        return str(re.findall(r'<a href="/heyzo_star/\S+">(\S+)</a> &nbsp;', response)).strip(" [',']").replace('\'', '')
    else:
        return str(re.findall(r'<b>å‡ºæ¼”è€…</b>: ([^<]+) &nbsp; <br>', response)).strip(" [',']").replace('\'', '')


def getStudio(html):
    result = str(html.xpath('//div[@class="col-md-9"]/a[contains(@href,"/company/")]/text()')).strip(" ['']")
    return result


def getRuntime(response):
    return str(re.findall(r'<b>åéŒ²æ™‚é–“</b>: (\d+) \S+<br>', response)).strip(" ['']")


def getSeries(html):
    result = str(html.xpath('//div[@class="col-md-9"]/a[contains(@href,"/series/")]/text()')).strip(" ['']")
    return result


def getWebsite(detail_page):
    return 'https:' + detail_page.xpath('//a[contains(text(),"ç®€ä½“ä¸­æ–‡")]/@href')[0]


def getNum(response, number):
    result = re.findall(r'<b>å“ç•ª</b>: (\S+)<br>', response)
    return result[0].strip().upper() if result else number


def getScore(response):
    if re.search(r'<b>å¹³å‡è©•ä¾¡</b>: <img data-original="/img/(\d+).gif" />', response):
        score = re.findall(r'<b>å¹³å‡è©•ä¾¡</b>: <img data-original="/img/(\d+).gif" />', response)[0]
        return str(float(score) / 10.0)
    else:
        return str(re.findall(r'<b>å¹³å‡è©•ä¾¡</b>: ([^<]+)<br>', response)).strip(" [',']").replace('\'', '')


def getYear(release):
    try:
        result = str(re.search(r'\d{4}', release).group())
        return result
    except:
        return release


def getRelease(response):
    return str(re.findall(r'<b>é…ä¿¡é–‹å§‹æ—¥</b>: (\d+-\d+-\d+)<br>', response)).strip(" ['']").replace('0000-00-00', '')


def getCover(detail_page):
    cover_url = str(detail_page.xpath("/html/body/div[@class='row'][2]/div[@class='col-md-3']/div[@class='col-xs-12 " "col-md-12'][1]/p/a/img[@class='img-responsive']/@src")).strip(
        " ['']")
    if cover_url == '':
        cover_url = str(detail_page.xpath("//*[@id='vjs_sample_player']/@poster")).strip(" ['']")
    return cover_url


def getExtraFanart(htmlcode):
    extrafanart_list = htmlcode.xpath("/html/body/div[@class='row'][2]/div[@class='col-md-3']/div[@class='col-xs-12 col-md-12']/p/a/img[@class='img-responsive']/@src")
    return extrafanart_list


def getCoverSmall(detail_page):
    return str(detail_page.xpath('//img[@class="img-responsive"]/@src')[0])


def getTag(response):  # è·å–æ¼”å‘˜
    return re.findall(r'<a href="/genre/\S+">(\S+)</a>', response)


def getOutline(detail_page):
    # ä¿®å¤è·¯å¾„ï¼Œé¿å…ç®€ä»‹å«æœ‰åƒåœ¾ä¿¡æ¯ "*æ ¹æ®åˆ†å‘æ–¹å¼ï¼Œå†…å®¹å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒâ€
    return detail_page.xpath("string(/html/body/div[2]/div[1]/div[1]/div[2]/div[3]/div/text())")


def main(number, appoint_url='', log_info='', req_web='', language='jp'):
    start_time = time.time()
    website_name = 'jav321'
    req_web += '-> %s' % website_name
    title = ''
    cover_url = ''
    poster_url = ''
    image_download = False
    image_cut = 'right'
    mosaic = 'æœ‰ç '
    web_info = '\n       '
    log_info += ' \n    ğŸŒ jav321'
    debug_info = ''

    try:
        result_url = "https://www.jav321.com/search"
        if appoint_url != '':
            result_url = appoint_url
            debug_info = 'ç•ªå·åœ°å€: %s' % result_url
            log_info += web_info + debug_info
        else:
            debug_info = 'æœç´¢åœ°å€: %s {"sn": %s}' % (result_url, number)
            log_info += web_info + debug_info
        result, response = post_html(result_url, data={"sn": number})
        if not result:
            debug_info = 'ç½‘ç»œè¯·æ±‚é”™è¯¯: %s' % response
            log_info += web_info + debug_info
            raise Exception(debug_info)
        if 'AVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ' in response:
            debug_info = 'æœç´¢ç»“æœ: æœªåŒ¹é…åˆ°ç•ªå·ï¼'
            log_info += web_info + debug_info
            raise Exception(debug_info)
        detail_page = etree.fromstring(response, etree.HTMLParser())
        website = getWebsite(detail_page)
        if website:
            debug_info = 'ç•ªå·åœ°å€: %s ' % website
            log_info += web_info + debug_info
        actor = getActor(response)
        actor_photo = getActorPhoto(actor)
        title = getTitle(response).strip()  # è·å–æ ‡é¢˜
        if not title:
            debug_info = 'æ•°æ®è·å–å¤±è´¥: æœªè·å–åˆ°æ ‡é¢˜ï¼'
            log_info += web_info + debug_info
            raise Exception(debug_info)
        cover_url = getCover(detail_page)  # è·å–cover
        poster_url = getCoverSmall(detail_page)
        if not cover_url:
            cover_url = poster_url
        release = getRelease(response)
        year = getYear(release)
        runtime = getRuntime(response)
        number = getNum(response, number)
        outline = getOutline(detail_page)
        tag = getTag(response)
        score = getScore(response)
        studio = getStudio(detail_page)
        series = getSeries(detail_page)
        extrafanart = getExtraFanart(detail_page)
        # åˆ¤æ–­æ— ç 
        uncensorted_list = ['ä¸€æœ¬é“', 'HEYZO', 'ã‚µãƒ ãƒ©ã‚¤ãƒãƒ«ãƒ', 'ã‚­ãƒ£ãƒƒãƒˆã‚¦ã‚©ãƒ¼ã‚¯', 'ã‚µã‚¤ã‚¯ãƒ­ãƒ³', 'ãƒ«ãƒãƒ£ãƒªãƒ–ãƒ¬', 'ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ¢ãƒ‡ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢', 'ã‚¹ã‚¿ã‚¸ã‚ªãƒ†ãƒªãƒ¤ã‚­',
                            'ãƒ¬ãƒƒãƒ‰ãƒ›ãƒƒãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³', 'ã‚¹ã‚«ã‚¤ãƒã‚¤ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ', 'å°å¤©ç‹—', 'ã‚ªãƒªã‚¨ãƒ³ã‚¿ãƒ«ãƒ‰ãƒªãƒ¼ãƒ ', 'Climax Zipang', 'CATCHEYE', 'ãƒ•ã‚¡ã‚¤ãƒ–ã‚¹ã‚¿ãƒ¼',
                            'ã‚¢ã‚¸ã‚¢ãƒ³ã‚¢ã‚¤ã‚º', 'ã‚´ãƒªãƒ©', 'ãƒ©ãƒ•ã‚©ãƒ¼ãƒ¬ ã‚¬ãƒ¼ãƒ«', 'MIKADO', 'ãƒ ã‚²ãƒ³ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ', 'ãƒ„ãƒã‚­ãƒã‚¦ã‚¹', 'ã‚¶ãƒ¼ãƒ¡ãƒ³äºŒéƒ', 'ãƒˆãƒ©ãƒˆãƒ©ãƒˆãƒ©',
                            'ãƒ¡ãƒ«ã‚·ãƒ¼ãƒœãƒ¼ã‚¯ãƒ¼', 'ç¥é¢¨', 'Queen 8', 'SASUKE', 'ãƒ•ã‚¡ãƒ³ã‚¿ãƒ‰ãƒªãƒ¼ãƒ ', 'ãƒãƒ„ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆ', 'ãƒ”ãƒ³ã‚¯ãƒ‘ãƒ³ãƒãƒ£ãƒ¼', 'ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹',
                            'ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ‰ãƒ©ã‚´ãƒ³', 'Tokyo Hot', 'Caribbean']
        for each in uncensorted_list:
            if each == studio:
                mosaic = 'æ— ç '
                break
        try:
            dic = {
                'number': number,
                'title': title,
                'originaltitle': title,
                'actor': actor,
                'outline': outline,
                'originalplot': outline,
                'tag': tag,
                'release': release,
                'year': year,
                'runtime': runtime,
                'score': score,
                'series': series,
                'director': '',
                'studio': studio,
                'publisher': studio,
                'source': 'jav321',
                'website': website,
                'actor_photo': actor_photo,
                'cover': cover_url,
                'poster': poster_url,
                'extrafanart': extrafanart,
                'trailer': '',
                'image_download': image_download,
                'image_cut': image_cut,
                'log_info': log_info,
                'error_info': '',
                'req_web': req_web + '(%ss) ' % (round((time.time() - start_time), )),
                'mosaic': mosaic,
                'wanted': '',
            }
            debug_info = 'æ•°æ®è·å–æˆåŠŸï¼'
            log_info += web_info + debug_info
            dic['log_info'] = log_info
        except Exception as e:
            debug_info = 'æ•°æ®ç”Ÿæˆå‡ºé”™: %s' % str(e)
            log_info += web_info + debug_info
            raise Exception(debug_info)

    except Exception as e:
        debug_info = str(e)
        dic = {
            'title': '',
            'cover': '',
            'website': '',
            'log_info': log_info,
            'error_info': debug_info,
            'req_web': req_web + '(%ss) ' % (round((time.time() - start_time), )),
        }
    dic = {website_name: {'zh_cn': dic, 'zh_tw': dic, 'jp': dic}}
    js = json.dumps(dic, ensure_ascii=False, sort_keys=False, indent=4, separators=(',', ': '), )  # .encode('UTF-8')
    return js


if __name__ == '__main__':
    # print(main('blk-495'))
    # print(main('hkgl-004'))
    # print(main('snis-333'))
    # print(main('GERK-326'))
    # print(main('msfh-010'))
    # print(main('msfh-010'))
    # print(main('kavr-065'))
    # print(main('ssni-645'))
    # print(main('sivr-038'))
    # print(main('ara-415'))
    # print(main('luxu-1257'))
    # print(main('heyzo-1031'))
    # print(main('ABP-905'))
    # print(main('heyzo-1031', ''))
    # print(main('ymdd-173', 'https://www.jav321.com/video/ymdd00173'))
    print(main('MIST-409'))
