import asyncio
import time
from io import BytesIO
from typing import Any, Callable, Literal, Optional

import httpx
from PIL import Image


class AsyncWebClient:
    def __init__(
        self,
        *,
        proxy: Optional[str] = None,
        retry: int = 3,
        timeout: Optional[httpx.Timeout] = None,
        default_headers: Optional[dict[str, str]] = None,
        log_fn: Optional[Callable[[str], None]] = None,
    ):
        limits = httpx.Limits(max_connections=100, max_keepalive_connections=50, keepalive_expiry=20)
        self.retry = retry
        self.default_headers = default_headers or {}
        # httpx ä¸æ”¯æŒä¸ºæ¯ä¸ªè¯·æ±‚å•ç‹¬è®¾ç½®ä»£ç†
        self.proxy_client = httpx.AsyncClient(
            limits=limits,
            proxy=proxy,
            verify=False,
            timeout=timeout,
            follow_redirects=True,
            max_redirects=10,
        )
        self.no_proxy_client = httpx.AsyncClient(
            limits=limits,
            verify=False,
            timeout=timeout,
            follow_redirects=True,
            max_redirects=10,
        )
        self.log_fn = log_fn if log_fn is not None else lambda _: None

    def _client(self, use_proxy):
        return self.proxy_client if use_proxy else self.no_proxy_client

    def _prepare_headers(self, url: Optional[str] = None, headers: Optional[dict[str, str]] = None) -> dict[str, str]:
        """é¢„å¤„ç†è¯·æ±‚å¤´"""
        if not headers:
            headers = self.default_headers.copy()

        # æ ¹æ®URLè®¾ç½®ç‰¹å®šçš„Referer
        if url:
            if "getchu" in url:
                headers.update({"Referer": "http://www.getchu.com/top.html"})
            elif "xcity" in url:
                headers.update(
                    {"referer": "https://xcity.jp/result_published/?genre=%2Fresult_published%2F&q=2&sg=main&num=60"}
                )
            elif "javbus" in url:
                headers.update({"Referer": "https://www.javbus.com/"})
            elif "giga" in url and "cookie_set.php" not in url:
                headers.update({"Referer": "https://www.giga-web.jp/top.html"})

        return headers

    async def request(
        self,
        method: Literal["GET", "POST", "PUT", "DELETE", "PATCH", "HEAD", "OPTIONS"],
        url: str,
        *,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
        data: Optional[dict[str, Any]] = None,
        json_data: Optional[dict[str, Any]] = None,
        timeout: Optional[httpx.Timeout] = None,
    ):
        """
        æ‰§è¡Œè¯·æ±‚çš„é€šç”¨æ–¹æ³•

        Args:
            url: è¯·æ±‚URL
            headers: è¯·æ±‚å¤´
            cookies: cookies
            use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†
            data: è¡¨å•æ•°æ®
            json_data: JSONæ•°æ®
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´, è¦†ç›–å®¢æˆ·ç«¯é»˜è®¤å€¼

        Returns:
            tuple[Optional[httpx.Response], str]: (å“åº”å¯¹è±¡, é”™è¯¯ä¿¡æ¯)
        """
        try:
            headers = self._prepare_headers(url, headers)
            retry_count = self.retry
            error_msg = ""
            for attempt in range(retry_count):
                try:
                    self.log_fn(f"ğŸ” {time.time()} {method} {url}" + f" ({attempt + 1}/{retry_count})" * (attempt != 0))
                    resp = await self._client(use_proxy).request(
                        method,
                        url,
                        headers=headers,
                        cookies=cookies,
                        data=data,
                        json=json_data,
                        timeout=timeout or httpx.USE_CLIENT_DEFAULT,
                    )
                    # æ£€æŸ¥å“åº”çŠ¶æ€
                    if resp.status_code >= 300 and not (resp.status_code == 302 and resp.headers.get("Location")):
                        error_msg = f"HTTP {resp.status_code}"
                        self.log_fn(f"ğŸ”´ è¯·æ±‚å¤±è´¥ {error_msg}")
                    else:
                        self.log_fn(f"âœ… è¯·æ±‚æˆåŠŸ {url}")
                        return resp, ""
                except httpx.TimeoutException:
                    error_msg = "è¯·æ±‚è¶…æ—¶"
                    self.log_fn(f"ğŸ”´ {error_msg} (å°è¯• {attempt + 1}/{retry_count})")
                except httpx.ConnectError as e:
                    error_msg = f"è¿æ¥é”™è¯¯: {str(e)}"
                    self.log_fn(f"ğŸ”´ {error_msg} (å°è¯• {attempt + 1}/{retry_count})")
                except Exception as e:
                    error_msg = f"è¯·æ±‚å¼‚å¸¸: {str(e)}"
                    self.log_fn(f"ğŸ”´ {error_msg} (å°è¯• {attempt + 1}/{retry_count})")
                # é‡è¯•å‰ç­‰å¾…
                if attempt < retry_count - 1:
                    await asyncio.sleep(attempt * 3 + 2)
            return None, f"{method} {url} å¤±è´¥: {error_msg}"
        except Exception as e:
            error_msg = f"{method} {url} å‘ç”ŸæœªçŸ¥é”™è¯¯:  {str(e)}"
            self.log_fn(f"ğŸ”´ {error_msg}")
            return None, error_msg

    async def get_text(
        self,
        url: str,
        *,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        encoding: str = "utf-8",
        use_proxy: bool = True,
    ) -> tuple[Optional[str], str]:
        """è¯·æ±‚æ–‡æœ¬å†…å®¹"""
        resp, error = await self.request("GET", url, headers=headers, cookies=cookies, use_proxy=use_proxy)
        if resp is None:
            return None, error
        try:
            resp.encoding = encoding
            return resp.text, error
        except Exception as e:
            return None, f"æ–‡æœ¬è§£æå¤±è´¥: {str(e)}"

    async def get_content(
        self,
        url: str,
        *,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
    ) -> tuple[Optional[bytes], Optional[str]]:
        """è¯·æ±‚äºŒè¿›åˆ¶å†…å®¹"""
        resp, error = await self.request("GET", url, headers=headers, cookies=cookies, use_proxy=use_proxy)
        if resp is None:
            return None, error

        return resp.content, None

    async def get_json(
        self,
        url: str,
        *,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
    ) -> tuple[Optional[dict[str, Any]], Optional[str]]:
        """è¯·æ±‚JSONæ•°æ®"""
        response, error = await self.request("GET", url, headers=headers, cookies=cookies, use_proxy=use_proxy)
        if response is None:
            return None, error
        try:
            return response.json(), None
        except Exception as e:
            return None, f"JSONè§£æå¤±è´¥: {str(e)}"

    async def post_text(
        self,
        url: str,
        *,
        data: Optional[dict[str, Any]] = None,
        json_data: Optional[dict[str, Any]] = None,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        encoding: str = "utf-8",
        use_proxy: bool = True,
    ) -> tuple[Optional[str], Optional[str]]:
        """POST è¯·æ±‚, è¿”å›å“åº”æ–‡æœ¬å†…å®¹"""
        response, error = await self.request(
            "POST", url, data=data, json_data=json_data, headers=headers, cookies=cookies, use_proxy=use_proxy
        )
        if response is None:
            return None, error
        try:
            response.encoding = encoding
            return response.text, None
        except Exception as e:
            return None, f"æ–‡æœ¬è§£æå¤±è´¥: {str(e)}"

    async def post_json(
        self,
        url: str,
        *,
        data: Optional[dict[str, Any]] = None,
        json_data: Optional[dict[str, Any]] = None,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
    ) -> tuple[Optional[dict[str, Any]], Optional[str]]:
        """POST è¯·æ±‚, è¿”å›å“åº”JSONæ•°æ®"""
        response, error = await self.request(
            "POST", url, data=data, json_data=json_data, headers=headers, cookies=cookies, use_proxy=use_proxy
        )
        if error or response is None:
            return None, error

        try:
            return response.json(), None
        except Exception as e:
            return None, f"JSONè§£æå¤±è´¥: {str(e)}"

    async def post_content(
        self,
        url: str,
        *,
        data: Optional[dict[str, Any]] = None,
        json_data: Optional[dict[str, Any]] = None,
        headers: Optional[dict[str, str]] = None,
        cookies: Optional[dict[str, str]] = None,
        use_proxy: bool = True,
    ) -> tuple[Optional[bytes], Optional[str]]:
        """POSTè¯·æ±‚, è¿”å›äºŒè¿›åˆ¶å“åº”"""
        response, error = await self.request(
            "POST", url, data=data, json_data=json_data, headers=headers, cookies=cookies, use_proxy=use_proxy
        )
        if error or response is None:
            return None, error

        return response.content, None

    async def get_filesize(self, url: str, *, use_proxy: bool = True) -> Optional[int]:
        """è·å–æ–‡ä»¶å¤§å°"""
        response, error = await self.request("HEAD", url, use_proxy=use_proxy)
        if response is None:
            self.log_fn(f"ğŸ”´ è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {error}")
            return None
        if response.status_code < 400:
            return int(response.headers.get("Content-Length"))
        return None

    async def download(self, url: str, file_path: str, *, use_proxy: bool = True) -> bool:
        """
        ä¸‹è½½æ–‡ä»¶. å½“æ–‡ä»¶è¾ƒå¤§æ—¶åˆ†å—ä¸‹è½½

        Args:
            url: ä¸‹è½½é“¾æ¥
            file_path: ä¿å­˜è·¯å¾„
            use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†

        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        # è·å–æ–‡ä»¶å¤§å°
        file_size = await self.get_filesize(url, use_proxy=use_proxy)
        # åˆ¤æ–­æ˜¯ä¸æ˜¯webpæ–‡ä»¶
        webp = False
        if file_path.endswith("jpg") and ".webp" in url:
            webp = True
        MB = 1024**2
        if not file_size or file_size <= 2 * MB or webp:
            # æ²¡æœ‰å¤§å°æ—¶, ä¸æ”¯æŒåˆ†æ®µä¸‹è½½, ç›´æ¥ä¸‹è½½; < 2 MB çš„ç›´æ¥ä¸‹è½½
            content, error = await self.get_content(url, use_proxy=use_proxy)
            if not content:
                self.log_fn(f"ğŸ”´ ä¸‹è½½å¤±è´¥: {error}")
                return False
            if webp:
                try:
                    byte_stream = BytesIO(content)
                    img: Image.Image = Image.open(byte_stream)
                    if img.mode == "RGBA":
                        img = img.convert("RGB")
                    img.save(file_path, quality=95, subsampling=0)
                    img.close()
                    return True
                except Exception as e:
                    self.log_fn(f"ğŸ”´ WebPè½¬æ¢å¤±è´¥: {str(e)}")
                    return False
            else:
                try:
                    with open(file_path, "wb") as f:
                        f.write(content)
                    return True
                except Exception as e:
                    self.log_fn(f"ğŸ”´ æ–‡ä»¶å†™å…¥å¤±è´¥: {str(e)}")
                    return False

        return await self._download_chunks(url, file_path, file_size, use_proxy)

    async def _download_chunks(self, url: str, file_path: str, file_size: int, use_proxy: bool = True) -> bool:
        """åˆ†å—ä¸‹è½½å¤§æ–‡ä»¶"""
        # åˆ†å—ï¼Œæ¯å— 1 MB
        MB = 1024**2
        each_size = min(1 * MB, file_size)
        parts = [(s, min(s + each_size, file_size)) for s in range(0, file_size, each_size)]

        self.log_fn(f"ğŸ“¦ åˆ†å—ä¸‹è½½: {len(parts)} ä¸ªåˆ†å—, æ€»å¤§å°: {file_size} bytes")

        # å…ˆåˆ›å»ºæ–‡ä»¶å¹¶é¢„åˆ†é…ç©ºé—´
        try:
            with open(file_path, "wb") as f:
                f.truncate(file_size)
        except Exception as e:
            self.log_fn(f"ğŸ”´ æ–‡ä»¶åˆ›å»ºå¤±è´¥: {str(e)}")
            return False

        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
        semaphore = asyncio.Semaphore(10)  # é™åˆ¶å¹¶å‘æ•°
        tasks = []

        for i, (start, end) in enumerate(parts):
            task = self._download_chunk(semaphore, url, file_path, start, end, i, use_proxy)
            tasks.append(task)

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä¸‹è½½ä»»åŠ¡
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            # æ£€æŸ¥æ‰€æœ‰ä»»åŠ¡æ˜¯å¦æˆåŠŸ
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    self.log_fn(f"ğŸ”´ åˆ†å— {i} ä¸‹è½½å¼‚å¸¸: {str(result)}")
                    return False
                elif not result:
                    self.log_fn(f"ğŸ”´ åˆ†å— {i} ä¸‹è½½å¤±è´¥")
                    return False
            self.log_fn(f"âœ… å¤šåˆ†å—ä¸‹è½½å®Œæˆ: {file_path}")
            return True
        except Exception as e:
            self.log_fn(f"ğŸ”´ å¹¶å‘ä¸‹è½½å¼‚å¸¸: {str(e)}")
            return False

    async def _download_chunk(
        self,
        semaphore: asyncio.Semaphore,
        url: str,
        file_path: str,
        start: int,
        end: int,
        chunk_id: int,
        use_proxy: bool = True,
    ) -> bool:
        """ä¸‹è½½å•ä¸ªåˆ†å—"""
        async with semaphore:
            res, error = await self.get_content(url, headers={"Range": f"bytes={start}-{end}"}, use_proxy=use_proxy)
            if res is None:
                self.log_fn(f"ğŸ”´ åˆ†å— {chunk_id} ä¸‹è½½å¤±è´¥: {error}")
                return False
        # å†™å…¥æ–‡ä»¶
        with open(file_path, "rb+") as fp:
            fp.seek(start)
            fp.write(res)
        self.log_fn(f"âœ… åˆ†å— {chunk_id} ä¸‹è½½å®Œæˆ ({start}-{end})")
        return True
